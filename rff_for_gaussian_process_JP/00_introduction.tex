% TeX source
%
% Author: Tetsuya Ishikawa <tiskw111@gmail.com>
% Date  : October 13, 2021
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% SOURCE START %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

本文書では，ガウス過程モデル~\cite{Rahimi2007}に
random Fourier features~\cite{Rasmussen2006} を適用する手順を解説します．
これにより，ガウス過程モデルの学習や推論を高速化させることができ，
より大規模なデータにガウス過程モデルを適用することができます．

ガウス過程モデル~\cite{Rahimi2007}は確率的教師あり機械学習フレームワークのひとつであり，
サポートベクトルマシンやランダムフォレストなどと並んで，回帰や分類タスクに広く使用されています．
ガウス過程モデルがサポートベクトルマシンやランダムフォレストと大きく違う点は「確率的なモデルである」ことです．
すなわち，ガウス過程モデルは確率的なモデルとして定式化されているため，予測値だけでなく，
その予測に対する不確実性の尺度をも提供することができます．
これは機械学習の説明性を上げることのできる非常に有益な性質です．

その一方で，ガウス過程モデルは学習や推論の計算コストが高いことでも知られています．
学習データの総数を$N \in \mathbb{Z}^{+}$としたとき，
ガウス過程モデルの学習に要する計算量は$O(N^3)$，推論に要する計算量は$O(N^2)$です．
問題は計算量が学習データの総数$N$のべき乗になってしまっていることで，これは大規模データへの適用に際して障害になり得ます．
これはガウス過程モデルがカーネル法と同等の数学的構造を有していることに起因しており，
言い変えれば，カーネルサポートベクトルマシンも同じ悩みを有しています．

カーネル法を高速化する手法のひとつにrandom Fourier features~\cite{Rasmussen2006}があります（以下 RFF と略します）．
これはカーネル関数を有限次元ベクトルの内積として近似することで，
カーネル法の柔軟性を維持しつつ計算量を大幅に削減する手法です．
具体的には学習に要する計算量を$O(N D^2)$，推論に要する計算量を$O(D^2)$にまで削減することができます．
ただし$D \in \mathbb{Z}^{+}$は RFF のハイパーパラメータであり，
学習データの総数$N$とは独立に指定することができます．

ガウス過程モデルはカーネル法と同等の数学的構造を有しているため，ガウス過程モデルにも RFF を適用することができます．
これにより，ガウス過程モデルはより強力かつお手軽に使える，非常に頼もしいツールへと進化します．


しかしながら，ガウス過程モデルへのRFFの適用にあたっては，実は一筋縄ではいかないところがあります．
ただRFFを適用するだけでは高速化につながらず，一工夫する必要があるのです．
ですが，そのあたりの困難さや解決方法に言及している文献が，残念ながら世の中には存在しないようでしたので，
本文書にてその手順を解説しようと考えた次第です．

ちなみに，本文書は拙作ライブラリ\texttt{rfflearn}~\cite{rfflearn}に同梱されているドキュメントの日本語版です．
おそらく\texttt{rfflearn}に同梱されている文書の方が頻繁にメンテナンスされると思いますので，
英語でも差し支えない方はそちらをご参照下さい．

\begin{displayquote}\footnotesize\textsf{NOTE:}
    上述のライブラリ \texttt{rfflearn} は以下で公開されています．
    \begin{center}
        \texttt{https://github.com/tiskw/random-fourier-features}
    \end{center}
\end{displayquote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% SOURCE FINISH %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% vim: expandtab tabstop=4 shiftwidth=4 fdm=marker
